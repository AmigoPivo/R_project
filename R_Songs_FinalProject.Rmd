## read files
library(readr)
library(kknn)
library(gbm)
set.seed(79643)

df_spotify <- read_csv("songDb.csv")
genres <- read_table("genre_dataset.txt", col_names = c('Genre'))
#View(df_spotify)

df_clean <- na.omit(df_spotify)

drop <- c('Uri','Name','Ref_Track', 'time_signature', 'Type', 'URL_features')
df_clean <- df_clean[, !(names(df_clean)%in%drop)]
df_clean <- df_clean[(df_clean$Duration_ms > 120000),]
#View(df_clean)
dim(df_clean)

df_genre <- df_clean
genres_aux = c('rock', 'pop', 'country','classical','hiphop','jazz','blues')
m_genre = matrix(data = NA, nrow = nrow(df_genre), ncol = 7)
colnames(m_genre) = genres_aux

for (x in genres_aux) {
  df_genre[grepl(x,df_genre$Genre),x] <- 1
  df_genre[!grepl(x,df_genre$Genre),x] <- 0
}

df_genre2 <- df_genre[rowSums(df_genre[15:21])==1,]
for (x in genres_aux){
  df_genre2[df_genre2[x]==1, 'genre'] = x
}
df_genre2 <- df_genre2[,!(names(df_genre2) %in% genres_aux)]
df_genre2$genre = factor(df_genre2$genre)
df_genre2$Tempo = as.numeric(df_genre2$Tempo)
dim(df_genre2)
View(df_genre2)
summary(df_genre2)

train = .7

train_sample = sample(1:nrow(df_genre2), nrow(df_genre2)*train)
train_df = df_genre2[train_sample,]
test_df = df_genre2[-train_sample,]


## Boxplots
test_data <- test_df
train_data <- train_df
boxplot(Danceability~genre,data=train_data, xlab="genre", ylab="Danceability")
boxplot(Energy~genre,data=train_data, xlab="genre", ylab="Energy")
boxplot(Key~genre,data=train_data, xlab="genre", ylab="Key")
boxplot(Loudness~genre,data=train_data, xlab="genre", ylab="Loudness")
boxplot(Mode~genre,data=train_data, xlab="genre", ylab="Mode")
boxplot(Speechness~genre,data=train_data, xlab="genre", ylab="Speechness")
boxplot(Acousticness~genre,data=train_data, xlab="genre", ylab="Acousticness")
boxplot(Instrumentalness~genre,data=train_data, xlab="genre", ylab="Instrumentalness")
boxplot(Liveness~genre,data=train_data, xlab="genre", ylab="Liveness")
boxplot(Valence~genre,data=train_data, xlab="genre", ylab="Valence")
boxplot(Tempo~genre,data=train_data, xlab="genre", ylab="Tempo")
boxplot(Duration_ms~genre,data=train_data, xlab="genre", ylab="Duration_ms")

# knn
library(class)
library(kknn)
set.seed(79643)
kk = c(20,30,40,50,60,70,80,90) #20,30,40,50,60,70,80,90
col = c(1:2,4,6:10,13)
Accuracy_knn = NULL
scale_train_data <- scale(train_data[,col]) 
scale_test_data <- scale(test_data[,col])
set.seed(1)
for(j in kk){
  nearest <- knn(train = scale_train_data, test = scale_test_data, cl=train_data$genre, k=j)
  aux =  mean(nearest == test_data$genre)
  Accuracy_knn = c(Accuracy_knn,aux)
    
}
plot(kk,Accuracy_knn,type="b",xlab="k",col="blue",ylab="Accuracy",lwd=2,cex.lab=1.2)
Accuracy_knn[which.max(Accuracy_knn)]

#regression tree
library(tree)
set.seed(79643)
df=train_df[,c(1:11,13,15)]
train = sample(1:nrow(df), nrow(df)*0.01)
tree.music=tree(genre~.,data=df,subset = train)
summary(tree.music)
plot(tree.music)
text(tree.music,pretty=0)
MSE=NULL
#estimate the test error using test dataset
#test=read.csv("test.csv")
test = test_df[,c(1:11,13,15)]
tree.pred = predict(tree.music,test,type="class")
result = data.frame(test$genre,tree.pred)
result[result$tree.pred == result$test.genre,"Equal"] <- 1
accuracy_tree = nrow(subset(result, result$Equal == 1)) / nrow(result)
accuracy_tree 

prun.tree=prune.tree(tree.music,best=8)
cat('pruned tree size: \n')
print(length(unique(prun.tree$where)))
#?? why prun tree = tree music? what does prune mean?
#plot the tree
par(mfrow=c(1,1))
plot(prun.tree,type="uniform")
options(digits=5)
text(prun.tree,pretty=0,col="blue",label=c("yprob"),cex=.8)
options(digits=7)


## Bagging 
library(randomForest)
set.seed (79643)
Accuracy_bagging = NULL
ntree <-c(50,200,500)
for (i in ntree){
  bag.music =randomForest(genre ~ Danceability + Energy + Key + Loudness + Mode + Speechness + Acousticness + Instrumentalness + Liveness + Valence + Tempo + Duration_ms, data=train_data ,
                          mtry=12, ntree = i) 
  
  yhat.bag = predict(bag.music,newdata = test_data)
  aux =  mean( yhat.bag == test_data$genre)
  Accuracy_bagging = c(Accuracy_bagging,aux)
}
plot(ntree, Accuracy_bagging,type="b",xlab="ntree",col="blue",ylab="Accuracy",lwd=2,cex.lab=1.2)
Accuracy_bagging[which.max(Accuracy_bagging)]


## Random Forest
library(dplyr)
library(randomForest) 



#--------------------------------------------------
#fit random forest and plot variable importance

# array of number of tree values to use
ntr<-c(50,200,500)
max_acc=0

# Training model with different number of trees and splits to get the optimal values for each
for (n in ntr){
  a=c()
  i=5
  for (i in 3:8) {
    model_rf <- randomForest(genre~.-ID-Genre, data = train_df, ntree = n, mtry = i, importance = TRUE)
    predValid <- predict(model_rf, newdata =test_df, type = "class")
    a[i-2] = mean(predValid == test_df$genre)
    if (a[i-2]>max_acc){
      max_acc=a[i-2]
      opt_tree=n
      opt_m=i
    }
    
  }
  print(paste0('Number of trees: ',n))
  print(a)
}

# training model with the optimal number of trees and splits
model_rf<-randomForest(genre~.-ID-Genre,data=train_df,ntree=opt_tree,mtry=opt_m,importance=TRUE)

# To check important variables
importance(model_rf)      

# plotting the importance of predictors
varImpPlot(model_rf) 


# Boosting
ntrees=5000
boostfit = gbm(genre~.-ID-Genre-Key-Mode,data=train_df,distribution='gaussian',
               interaction.depth=3,n.trees=ntrees,shrinkage=.2)
summary(boostfit)
varImpPlot(boostfit)


boostfit$response.name

pred = predict(boostfit,newdata=test_df,n.trees=ntrees)
length(pred)
summary(pred)

test_x = cbind(test_df$genre, pred)
View(test_df)
table(test_df$genre, round(pred))
